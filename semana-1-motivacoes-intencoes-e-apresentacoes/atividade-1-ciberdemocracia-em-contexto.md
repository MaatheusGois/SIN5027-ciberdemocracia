# Atividade 1: Ciberdemocracia em contexto

## Descrição da atividade

Busque na web fatos ou notícias contemporâneas relacionadas ao tema da disciplina.

Leia a notícia em sua totalidade.

Reflita a partir da notícia, nos seguintes pontos:

1. Porque a notícia te chamou a atenção?
2. Qual aspecto da ciberdemocracia é abordado na notícia?
3. Qual a questão, situação, problema é apresentado?
4. Qual a solução discutida ou desenvolvida?
5. Há resultados \(positivos ou negativos\)?
6. Qual a sua crítica em relação ao contexto problema, solução e resultados?
7. Haveria oportunidades para o desenvolvimento de pesquisas, desenvolvimento tecnológico e/ou inovação neste contexto?
8. Como?

## Notícia: [\[The Intercept Brasil\] Levantamento revela que 90,5% dos presos por monitoramento facial no Brasil são negros](https://theintercept.com/2019/11/21/presos-monitoramento-facial-brasil-negros/)

### **1. Porque a notícia te chamou a atenção?**

Como mestranda em Inteligência Artificial e engajada nas pautas raciais dentro desse tema, essa notícia me chamou muito a atenção e sempre costumo levá-la como exemplo nas minhas palestras sobre Inteligência Artificial e como ela propaga vieses discriminatórios, de vigilância e encarceramento. Podemos ver a tecnologia como uma nova ferramenta para o sistema racista em que o Brasil vive e precisamos entender como isso realmente acontece.

### 2. Qual aspecto da ciberdemocracia é abordado na notícia**?**

Sistemas de Informação de Governo Abertos e Colaborativos

### 3. Qual a questão, situação, problema é apresentado?

A Rede de Observatórios da Segurança realizou um levantamento que sobre os casos de prisões com o uso de reconhecimento facial e descobriu que, dos casos em que havia informações, 90,5% das pessoas presas eram negras.

### 4. Qual a solução discutida ou desenvolvida?

Uma das principais preocupações do texto é que essas tecnologias ainda apresentam diversos erros e vieses devido às bases de dados utilizadas para treinamento desses algoritmos.

O problema pior é que os erros dessa tecnologia podem representar constrangimentos e violações dos direitos das pessoas.

Diversos países e estados proíbem o uso dessa tecnologia já que não existe protocolo ou legislação a serem aplicados ao uso da tecnologia de reconhecimento facial.

### 5. Há resultados \(positivos ou negativos\)?

Não, até o momento não existem projetos no Brasil para regulamentação dessa tecnologia. Pelo contrário, o que existe em relação isso que o autor nos apresenta é: a criação do [Banco Nacional Multi biométrico e de impressões Digitais](https://www.justica.gov.br/news/collective-nitf-content-1549284631.06/projeto-de-lei-anticrime.pdf), proposto pelo ex-ministro da Justiça Sérgio Moro que, na verdade representa um retrocesso em relação à transparência, _accountability_ e proteção de dados pessoais da população brasileira.

### 6. Qual a sua crítica em relação ao contexto problema, solução e resultados?

Esse dado demonstra um problema muito conhecido nos Estados Unidos: automatização do encarceramento da população negra.

Um caso recente \(junho/2020\) nos estados unidos foi de um homem negro que foi [preso injustamente devido a um algoritmo](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html%20).

Além disso, esse ano, a IBM, Amazon e Microsoft interromperam a Pesquisa e Desenvolvimento de tecnologias de Reconhecimento Facial.

### 7. Haveria oportunidades para o desenvolvimento de pesquisas, desenvolvimento tecnológico e/ou inovação neste contexto? Como?

Acredito que sim. O pesquisador Pablo Nunes realiza trabalho nesse sentido através da [Rede de Observatórios da Segurança](http://observatorioseguranca.com.br/).

Assim como outras pesquisados do exterior nesse assunto:

* [Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products](https://www.media.mit.edu/publications/actionable-auditing-investigating-the-impact-of-publicly-naming-biased-performance-results-of-commercial-ai-products/)
* [MIT apologizes, permanently pulls offline huge dataset that taught AI systems to use racist, misogynistic slurs](https://www.theregister.com/2020/07/01/mit_dataset_removed/) \| [https://arxiv.org/pdf/2006.16923.pdf](https://arxiv.org/pdf/2006.16923.pdf)

As pesquisas tem se direcionado em alguns pontos, como:

* identificação de vieses discriminatórios em datasets de imagens públicos
* legislação de normas éticas em IA
* etc.

## **Leituras sugeridas**

* ARAUJO, R. M.; CAPPELLI, C. ; DIIRR, B. ; ENGIEL, P. ; TAVARES, R. L. . [Democracia Eletrônica. In: Mariano Pimentel; Hugo Fuks. \(Org.\). Sistemas Colaborativos](https://sistemascolaborativos.uniriotec.br/). 1ed.Rio de Janeiro: Campus/SBC, 2011, v. , p. 110-121.
* ARAUJO, R. M.. Information Systems and the Open World Challenges. In: Clodis Boscarioli; Renata Araujo, Rita Suzana Maciel. \(Org.\). [I GranDSI-BR ? Grand Research Challenges in Information Systems in Brazil 2016-2026](https://sol.sbc.org.br/livros/index.php/sbc/catalog/book/28). 1ed.Porto Alegre: Sociedade Brasileira de Computação, 2017, v. 1, p. 42-51.
* ARAUJO, R.M. [Sistemas de Informação para Ciberdemocracia](https://edisciplinas.usp.br/pluginfile.php/5488543/course/section/6002971/ARAUJO_SistemasdeInforma%C3%A7%C3%A3oCiberdemocracia.pdf). \(em publicação pela FGV\).

